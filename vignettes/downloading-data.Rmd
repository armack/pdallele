---
title: "Download Data from NCBI and Other Sources"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{download-data}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

```{r setup}
```
## Introduction
This guide covers the step-by-step process of downloading all the data required to perform a detailed analysis of the alleles present in 

## Set FTP Directories
Specify the directories on the NCBI FTP server containing the data of interest.
```{r, eval = FALSE}
ftp_results_base <- "ftp://ftp.ncbi.nlm.nih.gov/pathogen/Results/"
ftp_refgene_base <- "ftp://ftp.ncbi.nlm.nih.gov/pathogen/Antimicrobial_resistance/Data/"
```

## Step One - Select the organism group of interest
```{r, eval = FALSE}
organism <- select_ftp_organism(ftp_results_base)
```

## Step Two - Select a version of the data to download
```{r, eval = FALSE}
version <- select_ftp_version(ftp_results_base, organism)
```

## Step Three - Specify a path to save downloaded data
```{r, eval = FALSE}
data_path <- file.path(getwd(), "data/Pseudomonas")
```

## Step Four - Download AMR and Cluster Data (NCBI FTP)
```{r, eval = FALSE}
download_metadata_clusters(ftp_results_base, organism, version, data_path)
```

## Step Five - Download Reference Gene Catalog Data (NCBI FTP)
```{r, eval = FALSE}
refgene_version <- select_ftp_refgene(ftp_refgene_base)
download_reference_gene_catalog(ftp_refgene_base, refgene_version, data_path)
```

## Step Six - Download MicroBIGG-E Data (Google Cloud)
Filter by "taxgroup" to match the organism group from step one or by
"sciname" to match to a specific genus/species at the isolate level.
Optionally, filter by "element" to limit to a specific type of allele,
such as "%bla%" to filter only beta-lactamase alleles. Use '%' as a wildcard.

Note that "taxgroup_name" matches organism group names from
https://www.ncbi.nlm.nih.gov/pathogens/organisms/ and that "Escherichia coli
Shigella" becomes "E.coli and Shigella".

Set `gcp_billing` to your GCP billing code. See bigrquery help at
https://bigrquery.r-dbi.org for more information about connecting to BigQuery
using R.

```{r, eval = FALSE}
download_microbigge_bq(
  billing = gcp_billing,
  path = data_path,
  taxgroup = "Pseudomonas aeruginosa",
  element = "%bla%"
)
```

## Step Seven - Download Identical Protein Groups Data (NCBI Entrez)
```{r, eval = FALSE}
import_microbigge_gcp(file.path(data_path, "microbigge.tsv")) %>%
  possible_unique_proteins() %>%
  download_identical_protein_groups(n = 25, path = data_path)
```

## Step Eight (Optional) - Determine Genomes to Download for MLST
See `vignette("mlst")` for more information on downloading assemblies and
determining MLST

Path to NCBI Assembly Summary. This is a very large (~975 MB as of August 2024) file so it may be
useful to keep one local copy when downloading data for multiple organisms

```{r, eval = FALSE}
genome_data_path <- file.path(data_path, "all_bacteria_assemblies.tsv")
```

### Download NCBI FTP Genome Details (If Needed).
```{r, eval = FALSE}
options(timeout = 300)
utils::download.file(url = "ftp://ftp.ncbi.nlm.nih.gov/genomes/genbank/bacteria/assembly_summary.txt",
                     destfile = genome_data_path)
```

### Load Genome Details
```{r, eval = FALSE}
genomes <-
  readr::read_tsv(file = genome_data_path, skip = 2,
           col_types = "c-c----------------c------------------",
           col_names = c(
             "assembly",
             "biosample",
             "ftp_base"
           )
  )
```

### Determine Assemblies Needed
```{r, eval = FALSE}
assemblies_to_download <-
  import_microbigge_gcp(file.path(data_path, "microbigge.tsv")) %>%
  dplyr::distinct(assembly) %>%
  dplyr::pull(assembly)
```

### Generate and Save FTP Paths to File
```{r, eval = FALSE}
genomes %>%
  dplyr::filter(assembly %in% assemblies_to_download) %>%
  dplyr::mutate(ftp_url = paste0(ftp_base, "/", basename(ftp_base), "_genomic.fna.gz")) %>%
  dplyr::pull(ftp_url) %>%
  readr::write_lines(file = file.path(data_path, "assemblies_to_download.txt"))
```

## Step Nine - Determine Sequence Types (Optional)
### Download and unzip assemblies
This can be accomplished using any tool that
allows bulk downloading and unzipping from a list of URLs. This can easily be
acomplished using the command line or terminal tools.

Using the terminal, one approach is to use xargs and wget:

`cat path/to/assemblies_to_download.txt | shuf | xargs -n10 -P4 wget --continue -P /path/to/save/genomes -q -nc --show-progress --progress=bar:force:noscroll`

The genomes can then be decompressed using:
`
cd /path/to/save/genomes
gunzip *.gz
`

### Determine Sequence Types
Sequence types should be determiend using FastMLST, which is available from
https://github.com/EnzoAndree/FastMLST and described in "FastMLST: A Multi-core
Tool for Multilocus Sequence Typing of Draft Genome Assemblies" by
Guerrero-Araya et al. available at
https://www.ncbi.nlm.nih.gov/pmc/articles/PMC8637782/.


#### Running FastMLST
See the official documentation for FastMLST at
https://github.com/EnzoAndree/FastMLST/blob/master/README.md for guidance on how
to run FastMLST and the various options available.

The only specific requirement for use with the `pdallele` package is that the
output must be in CSV format.

Setting both "coverage" and "identity" to 100 ensures only exact matches are
used when calling specific alleles, leading to more precise results.

An example with *Pseudomonas aeruginosa*:

`fastmlst /path/to/save/genomes/*.fna -to /path/to/output/fastmlst.csv -cov 100 -pid 100 --scheme "paeruginosa"`

The output from FastMLST can be easily reprocessed using the following
procedure to provide more granular detail about individual isolates and to
update sequence types to newer versions of the database without needing to
re-run FastMLST.

#### Reprocessing FastMLST Output
Run the following command, where `raw_mlst_path` is the path to the CSV output
of FastMLST. This will automatically save a reprocessed CSV file with
"_reprocessed" appended in the same directory. This reprocessed file should be
used when loading data for analysis using `pdallele`.
```{r, eval = FALSE}

reprocess_mlst(raw_mlst_path)
```
